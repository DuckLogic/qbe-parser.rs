pub mod tokens;

use crate::ast::{
    BlockName, GlobalName, Ident, Span, Spanned, StringLiteral, TemporaryName, TypeName,
};
use chumsky::input::MapExtra;
use chumsky::prelude::*;

pub use tokens::{Keyword, Operator, ShortTypeSpec, Token};
pub(crate) use tokens::{keyword, operator, short_type_spec};

type ParserExtra<'a, T> = extra::Err<Rich<'a, T>>;
macro_rules! parser_trait_alias {
    ($v:vis trait $name:ident<$l:lifetime, $output:ident>: $($bound:tt)*) => {
        $v trait $name<$l, $output>: $($bound)* {}
        impl<$l, $output, T> $name<$l, $output> for T
            where T: $($bound)* {}
    };
}
pub type TokenStream<'a> = &'a [Token];
parser_trait_alias!(pub(crate) trait TokenParser<'a, O>: Parser<'a, TokenStream<'a>, O, ParserExtra<'a, Token>>);
parser_trait_alias!(pub(crate) trait StringParser<'a, O>: Parser<'a, &'a str, O, ParserExtra<'a, char>>);

fn token<'a>() -> impl StringParser<'a, Token> {
    macro_rules! prefixed_idents {
        ($($target:ident),+ $(,)?) => ({
            choice((
                $(prefixed_idents!(@specific $target),)*
            ))
        });
        (@specific $target:ident) => ({
            just($target::PREFIX)
                .ignore_then(ident())
                .map_with(spanned)
                .labelled($target::label())
                .map(|x| Token::$target($target::new(x.value, x.span)))
        });
    }
    let prefixed_idents = prefixed_idents!(TypeName, GlobalName, TemporaryName, BlockName,);
    // A single token
    choice((
        Operator::text_parser().map_with(spanned).map(Token::from),
        Keyword::text_parser()
            .map_with(spanned)
            .map(Token::from)
            .labelled("keyword"),
        ShortTypeSpec::text_parser()
            .map_with(spanned)
            .map(Token::from)
            .labelled("type specifier"),
        ident().map(Token::Ident),
        prefixed_idents,
        string_literal().map(Token::StringLiteral),
    ))
    .labelled("token")
    .boxed()
}
pub(crate) fn tokenizer<'a>() -> impl StringParser<'a, Vec<Token>> {
    // Unlike text::newline, this only accepts ASCII newline operators
    // TODO: Contribute this to chumsky?
    let newline = one_of("\r\n")
        .ignored()
        .or(just("\r\n").ignored())
        .labelled("newline");
    let comment = just('#')
        .then(newline.not().repeated())
        .then(newline)
        .labelled("comment");
    // Loosely based on the tokenizer in the nano_rust example
    // https://github.com/zesterer/chumsky/blob/0.11/examples/nano_rust.rs#L95-L102
    token()
        .padded_by(comment.repeated())
        .padded()
        // If we encounter an error, skip and attempt to lex the next character as a token instead.
        // This strategy was copied from the nano_rust example:
        .recover_with(skip_then_retry_until(any().ignored(), end()))
        .repeated()
        .collect()
}

#[derive(Debug, thiserror::Error)]
#[error("Failed to tokenize input")]
pub struct LexError(Rich<'static, char>);
impl LexError {
    pub(crate) fn from_rich_list(value: Vec<Rich<'_, char>>) -> Self {
        Self::from_rich(value.into_iter().next().expect("empty error list"))
    }
    pub(crate) fn from_rich(rich: Rich<'_, char>) -> Self {
        LexError(rich.into_owned())
    }
}

/// Tokenize the specified input.
pub fn tokenize(text: &str) -> Result<Vec<Token>, LexError> {
    tokenizer()
        .parse(text)
        .into_result()
        .map_err(LexError::from_rich_list)
}

fn spanned<'a, T>(
    value: T,
    extra: &mut MapExtra<'a, '_, &'a str, ParserExtra<'a, char>>,
) -> Spanned<T> {
    Spanned {
        value,
        span: extra.span().into(),
    }
}
fn ident<'a>() -> impl StringParser<'a, Ident> {
    text::ident()
        .map_with(spanned)
        .map(Ident::from)
        .labelled("identifier")
}
/// Parses an escape character generated by [`char::escape_default`].
fn string_escape_char<'a>() -> impl StringParser<'a, char> {
    let unicode_escape_value = any()
        .filter(char::is_ascii_hexdigit)
        .repeated()
        .at_least(1)
        .at_most(6)
        .to_slice()
        .map(|x| u32::from_str_radix(x, 16).expect("cannot fail"))
        .delimited_by(just("{"), just("}"));
    let unicode_escape = just("\\u")
        .ignore_then(unicode_escape_value)
        .try_map(|value, span| {
            char::from_u32(value)
                .ok_or_else(|| Rich::custom(span, "Unicode escape references invalid codepoint"))
        })
        .labelled("unicode escape");
    let basic_escape = just('\\').ignore_then(any()).try_map(|x, span| {
        Ok(match x {
            'n' => '\n',
            't' => '\t',
            'r' => '\r',
            '0' => '\0',
            '\\' | '\'' | '"' => x, // these escape chars correspond to their own values
            _ => return Err(Rich::custom(span, "Unknown escape character")),
        })
    });
    unicode_escape.or(basic_escape).labelled("escape char")
}
fn string_literal<'a>() -> impl StringParser<'a, StringLiteral> {
    // needs to be able to reverse
    let string_part = none_of(['\\', '"']).or(string_escape_char());
    string_part
        .repeated()
        .collect::<String>()
        .delimited_by(just("\""), just("\""))
        .map_with(spanned)
        .map(StringLiteral::from)
        .labelled("string literal")
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn operators() {
        assert_eq!(token().parse("=").unwrap(), operator!(=).into());
        assert_eq!(
            tokenize("= :").unwrap(),
            vec![operator!(=), operator!(:)]
                .into_iter()
                .map(Token::from)
                .collect::<Vec<_>>(),
        )
    }
}
